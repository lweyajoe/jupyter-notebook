{"cells":[{"metadata":{"_cell_guid":"ebcc46ed-aa04-4913-9796-a2baf1fa3064","_uuid":"bef46e5445421a341281938eb901ba23e9361646"},"cell_type":"markdown","source":"# **Market Basket Analysis - Exploring eCommerce data**\n\n**This Kernel was used as a presentation material for the Intertalent Conference at University of Debrecen , Hungary 2018**\n\n**Introduction**\n\nMy first experience with Market Basket Analysis (MBA) projects was in Brazil, deploying this particular solution to a Retail tech company focused on improving marketing performance working data-driven. By that time my analytical team had good knowledge of statistics but no Python practice at all, therefore, in order to keep with the project we worked entirely on [RapidMiner](http://rapidminer.com). This platform has improved a lot since our first experiments, and even though many people would prefer to jump into the code learning curve, I still strongly suggest starting with code-free software like RapidMiner for getting a sense of how Data Science could work for you and your company.\nThis Kernel is basically a similar python implementation of the same technology used with some extra time series analysis. Association rules are powerful for marketing and could be an initial source for recommendation systems.\n\nThis article from KDNuggets is a great place to start in case you've never seen MBA Implementations and statistics involved: https://bit.ly/2qzxh8H \n\n**This notebook is structured as follows:**\n\n    1. Loading libraries and data\n    2. Handling missing data with missingno library\n          2.1 Data Loss Management (DLM)\n    3. Data visualization\n    4. Frequent sets and association rules with apriori\n    5. Conclusions\n   "},{"metadata":{"_cell_guid":"8fe636e1-ab24-49d1-9f97-7a79bb2292b4","_uuid":"5a76c62fcf40626bcb74054783f418529a561d85"},"cell_type":"markdown","source":"# 1. Loading libraries and data:"},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"c73d65856bd8088b88aeb7ee6a0757beeacaa944","_cell_guid":"95c6af05-6bea-4ded-b328-04a4c682731b","_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n# Loading libraries for python\nimport numpy as np # Linear algebra\nimport pandas as pd # Data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # Data visualization\nimport seaborn as sns # Advanced data visualization\nimport re # Regular expressions for advanced string selection\nfrom mlxtend.frequent_patterns import apriori # Data pattern exploration\nfrom mlxtend.frequent_patterns import association_rules # Association rules conversion\nfrom mlxtend.preprocessing import OnehotTransactions # Transforming dataframe for apriori\nimport missingno as msno # Advanced missing values handling\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{"_kg_hide-input":true,"scrolled":true,"_uuid":"9eaca0e05649e67c1001cd79eb35ae2fbe3c9944","_cell_guid":"cd9baf41-8845-4291-9ef5-9fba2de97ecd","trusted":true},"cell_type":"code","source":"# Reading input, converting InvoiceDate to TimeStamp, and setting index: df\n# Note that we're working only with 30000 rows of data for a methodology concept proof \ndf = pd.read_csv('../input/data.csv', nrows=30000)\ndf.InvoiceDate = pd.to_datetime(df.InvoiceDate)\ndf.set_index(['InvoiceDate'] , inplace=True)\n\n# Dropping StockCode to reduce data dimension\n# Checking df.sample() for quick evaluation of entries\ndf.drop('StockCode', axis=1, inplace=True)\ndf.sample(5, random_state=42)","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"c20f3c7f-e732-44cc-ad13-25b9e4fbec94","_uuid":"ffd091ac11301c5d11c472694918bb7493685761"},"cell_type":"markdown","source":"# 2. Handling missing data with missingno library:"},{"metadata":{"_uuid":"41cd692197d1fc08f5eff87575eadbff5aba3ba7","_cell_guid":"6a445fe7-78a7-4748-80e1-1b425ec1ad17","trusted":true},"cell_type":"code","source":"# Checking missing and data types\n# Experimenting missingno library for getting deeper understanding of missing values \n# Checking functions on msno with dir(msno)\nprint(df.info())\nmsno.bar(df);\nmsno.heatmap(df);\n\n# InvoiceNo should be int64, there must be something wrong on this variable\n# When trying to use df.InvoiceNo.astype('int64') we receive an error \n# stating that it's not possible to convert str into int, meaning wrong entries in the data.","execution_count":3,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a988fad5c419b3258c640dfc4d605040397be5d6","_cell_guid":"096f2c62-3287-437a-bb95-1f122c92a913","trusted":true},"cell_type":"code","source":"# Zoming into missing values\n# On df.head() only CustomerID is missing\n# We notice the same problem in Description when exploring find_nans a bit\nfind_nans = lambda df: df[df.isnull().any(axis=1)]","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"658a2195-b50b-4d48-87e9-c9ca72c815fd","_uuid":"cc80074d3c15b0e2767c7aaa95bc88c334aeb596"},"cell_type":"markdown","source":"## 2.1 Data Loss Management (DLM)"},{"metadata":{"_uuid":"630808acc33fae515bbff3a55f3132fa296cd4ac","_cell_guid":"4b6c31b3-8ad0-4ee0-8b54-72e285372d7a","trusted":true},"cell_type":"code","source":"# For a data loss management (dlm) we will track data dropped every .drop() step\ndlm = 0\nog_len = len(df.InvoiceNo)\n\n# It does not matter not having CustomerID in this analysis\n# however a NaN Description shows us a failed transaction\n# We will drop NaN CustomerID when analysing customer behavior \ndf.dropna(inplace=True, subset=['Description'])\n\n# data_loss report\nnew_len = len(df.InvoiceNo)\ndlm += (og_len - new_len)\nprint('Data loss report: %.2f%% of data dropped, total of %d rows' % (((og_len - new_len)/og_len), (og_len - new_len)))\nprint('Data loss totals: %.2f%% of total data loss, total of %d rows\\n' % ((dlm/og_len), (dlm)))\nmod_len = len(df.InvoiceNo)\ndf.info()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"af01caca065a11d5c99c5d07c6548d24ae3606ca","_cell_guid":"b54a23cc-8130-4c32-b67c-adb75f48756a","trusted":true},"cell_type":"code","source":"# Note that for dropping the rows we need the .index not a boolean list\n# to_drop is a list of indices that will be used on df.drop()\nto_drop = df[df.InvoiceNo.str.match('^[a-zA-Z]')].index\n\n# Droping wrong entries starting with letters\n# Our assumption is that those are devolutions or system corrections\ndf.drop(to_drop, axis=0, inplace=True)\n\n# Changing data types for reducing dimension and make easier plots\ndf.InvoiceNo = df.InvoiceNo.astype('int64')\ndf.Country = df.Country.astype('category')\nnew_len = len(df.InvoiceNo)\n\n# data_loss report\nnew_len = len(df.InvoiceNo)\ndlm += (mod_len - new_len)\nprint('Data loss report: %.2f%% of data dropped, total of %d rows' % (((mod_len - new_len)/mod_len), (mod_len - new_len)))\nprint('Data loss totals: %.2f%% of total data loss, total of %d rows' % ((dlm/og_len), (dlm)))\nmod_len = len(df.InvoiceNo)","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"54b1eb36-2c43-4c95-9b5d-55c4fca1e007","_uuid":"3813c767d6c5bcebbc1af7a9f2d8326ad74107d8"},"cell_type":"markdown","source":"# 3. Data visualization:"},{"metadata":{"scrolled":true,"_uuid":"82fc7119a103fe5cf857ec10f06e0a4601a6012d","_cell_guid":"2070f224-060a-4e02-bafa-4e2ee7170d9c","trusted":true},"cell_type":"code","source":"# Checking categorical data from df.Country\n# unique, counts = np.unique(df.Country, return_counts=True)\n# print(dict(zip(unique, counts)))\ncountry_set = df[['Country', 'InvoiceNo']]\ncountry_set = country_set.pivot_table(columns='Country', aggfunc='count')\ncountry_set.sort_values('InvoiceNo', axis=1, ascending=False).T","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"f66a4957c38451dde10614e5d184373ccb7095f7","_cell_guid":"15eff4e5-c31e-4cbd-a45a-b690c3bb8688","trusted":true},"cell_type":"code","source":"# Plotting InvoiceNo distribution per Country\nplt.figure(figsize=(14,6))\nplt.title('Distribuition of purchases in the website according to Countries');\nsns.countplot(y='Country', data=df);","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"13f1d086163430c5c19625a2c302cb00d085764d","_cell_guid":"e15bff25-2084-4acc-b49c-ddbb0e6e9c74","trusted":true},"cell_type":"code","source":"# Plotting InvoiceNo without United Kingdom\ndf_nUK = country_set.T.drop('United Kingdom')\nplt.figure(figsize=(14,6))\nplt.title('Distribuition of purchases in the website according to Countries');\n# Note that since we transformed the index in type category the .remove_unused_categories is used\n# otherwise it woul include a columns for United Kingdom with 0 values at the very end of the plot\nsns.barplot(y=df_nUK.index.remove_unused_categories(), x='InvoiceNo', data=df_nUK, orient='h');","execution_count":9,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_uuid":"dcb09d29e99c8af149611ac37e4ab8651cdd762e","_cell_guid":"aacdde32-aac1-4f86-8e17-542409624e08","collapsed":true,"trusted":true},"cell_type":"code","source":"# Creating subsets of df for each unique country\ndef df_per_country(df):\n    df_dict = {}\n    unique_countries, counts = np.unique(df.Country, return_counts=True)\n    for country in unique_countries:\n        df_dict[\"df_{}\".format(re.sub('[\\s+]', '', country))] = df[df.Country == country].copy()\n        # This line is giving me the warning, I will check in further research\n        # After watching Data School video about the SettingWithCopyWarning I figured out the problem\n        # When doing df[df.Country == country] adding the .copy() points pandas that this is an actual copy of the original df\n        df_dict[\"df_{}\".format(re.sub('[\\s+]', '', country))].drop('Country', axis=1, inplace=True)\n    return df_dict\n\n# Trick to convert dictionary key/values into variables\n# This way we don't need to access dfs by df_dict['df_Australia'] for example\ndf_dict = df_per_country(df)\nlocals().update(df_dict)","execution_count":10,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"c1ac2c31308fc869c82586f53831860bda6c9f76","_cell_guid":"a5f93d27-cfa7-4fab-9c1a-eb4b1208558c","trusted":true},"cell_type":"code","source":"# Series plot function summarizing df_Countries\ndef series_plot(df, by1, by2, by3, period='D'):\n    df_ts = df.reset_index().pivot_table(index='InvoiceDate', \n                                values=['InvoiceNo', 'Quantity', 'UnitPrice'], \n                                aggfunc=('count', 'sum'))\n    df_ts = df_ts.loc[:, [('InvoiceNo', 'count'), ('Quantity', 'sum'), ('UnitPrice', 'sum')]]\n    df_ts.columns = df_ts.columns.droplevel(1)\n    plt.figure(figsize=(14, 6))\n    \n    plt.subplot(2, 2, 1)\n    plt.plot(df_ts.resample(period).sum().bfill()[[by1]], color='navy')\n    plt.title('{}'.format(by1));\n    plt.xticks(rotation=60);\n    plt.subplot(2, 2, 2)\n    plt.title('{}'.format(by2));\n    plt.plot(df_ts.resample(period).sum().bfill()[[by2]], label='Total Sale', color='orange');\n    plt.xticks(rotation=60)\n    plt.tight_layout()\n    \n    plt.figure(figsize=(14, 8))\n    plt.title('{}'.format(by3));\n    plt.plot(df_ts.resample(period).sum().bfill()[[by3]], label='Total Invoices', color='green');\n    plt.tight_layout()","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"6082e9087ddbfb2e886d197176f5d87fdb373d42","_cell_guid":"f68a7535-9acc-4e3f-ba66-992c9fc6d990","trusted":true},"cell_type":"code","source":"series_plot(df_UnitedKingdom, 'Quantity', 'UnitPrice', 'InvoiceNo')","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"26fd2623-6d40-486f-942f-d724ec6fb230","_uuid":"91a1480d96ca1f03bd4defdfc87cf6d71a11f3cf"},"cell_type":"markdown","source":"# 4. Frequent sets and association rules with apriori:"},{"metadata":{"collapsed":true,"_uuid":"b6709576e86a5203e6a637eb1f42806ed01e53f5","_cell_guid":"b04ff7ba-7153-4e3f-963e-20746f32d2ee","trusted":true},"cell_type":"code","source":"# Starting preparation of df for receiving product association\n# Cleaning Description field for proper aggregation \ndf_UnitedKingdom.loc[:, 'Description'] = df_UnitedKingdom.Description.str.strip().copy()\n# Once again, this line was generating me the SettingWithCopyWarning, solved by adding the .copy()\n\n# Dummy conding and creation of the baskets_sets, indexed by InvoiceNo with 1 corresponding to every item presented on the basket\n# Note that the quantity bought is not considered, only if the item was present or not in the basket\nbasket = pd.get_dummies(df_UnitedKingdom.reset_index().loc[:, ('InvoiceNo', 'Description')])\nbasket_sets = pd.pivot_table(basket, index='InvoiceNo', aggfunc='sum')","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"761aa92c52775994a2cfe7a332b6dd41962df612","_cell_guid":"f7bf94c3-a324-4ff8-acc1-b5c6041fd160","trusted":true},"cell_type":"code","source":"# Apriori aplication: frequent_itemsets\n# Note that min_support parameter was set to a very low value, this is the Spurious limitation, more on conclusion section\nfrequent_itemsets = apriori(basket_sets, min_support=0.03, use_colnames=True)\nfrequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n\n# Advanced and strategical data frequent set selection\nfrequent_itemsets[ (frequent_itemsets['length'] > 1) &\n                   (frequent_itemsets['support'] >= 0.02) ].head()","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"4cf30c61db90d6042c79bb9f06d8685e2811aa05","_cell_guid":"8bc2c8fc-f5a8-41d0-ad17-a3d2e273716d","trusted":true},"cell_type":"code","source":"# Generating the association_rules: rules\n# Selecting the important parameters for analysis\nrules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\nrules[['antecedants', 'consequents', 'support', 'confidence', 'lift']].sort_values('support', ascending=False).head()","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"5a229d082c8bbf2ac19977b5e3aed9edbd734d85","_cell_guid":"7bcdd8eb-e592-4fa6-a607-5a7afe348d7b","trusted":true},"cell_type":"code","source":"# Visualizing the rules distribution color mapped by Lift\nplt.figure(figsize=(14, 8))\nplt.scatter(rules['support'], rules['confidence'], c=rules['lift'], alpha=0.9, cmap='YlOrRd');\nplt.title('Rules distribution color mapped by lift');\nplt.xlabel('Support')\nplt.ylabel('Confidence')\nplt.colorbar();","execution_count":17,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"09d03ecb8e0c39bf89977972ea68cff41e3c628e","_cell_guid":"554b9bc4-752a-4396-9d40-8069edc288c4"},"cell_type":"markdown","source":"# 5. Conclusions:\n"},{"metadata":{"_cell_guid":"3e548be6-7808-4cc4-965c-28fd6766b032","_uuid":"57997098419631e5d5b127809f1505408c8e8644"},"cell_type":"markdown","source":"### Potential of the solution\nIn Brazil we achieved impressive results in terms of applied marketing using this particular solution. Even though it's simple, one needs to take into consideration that for countries or sectors starting with analytics going from zero to an actual data-driven solution is already a game-changer.\n\n### Implementation simplicity\nOnce again, the implementation of the solution in terms of code is simple. Deployement in most cases can be report based exporting the relevant rules for discussion.\n\n### Statistical interpretation\nThe statistical interpretation of how support, confidence and lift can correlate with marketing strategies take some time and know how on the field where it's being applied. [Start here](http://analyticstrainings.com/?p=151) for explanations about the output attributes from this model.\n\n### Apriori limitations\nAs seen on the KDNuggets article referenced in the Introduction, we faced the Spurious Associations limitation. This happend due to the eCommerce business model, a large number of possibilities in a single basket among an even larger number of baskets. The consequence of it is having a \"sparse matrix\", full of 0s which causes the support of basket occourances to drop drastically. The output achieved has its top support of 0.051 (5%).\nSuch limitation might be overcome by working with the entire data set, remember that only 30000 top rows were analysed, or this could dilute the support values even more. As a last optio"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}